{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is a way to export the pytorch model in .ONNX format."
      ],
      "metadata": {
        "id": "-I4qdngWhfWF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PekAC0rGdsfM"
      },
      "outputs": [],
      "source": [
        "# Load the required libraries\n",
        "!pip install transformers[onnx]\n",
        "!pip install optimum\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "IDEhLH5rf-2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# link to the model that you want to export inside \" \"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"yashika0998/IoT-23-BERT-Network-Logs-Classification\")"
      ],
      "metadata": {
        "id": "Vlw6Z5lmgEe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy input is a single input in which the model expects a input. I have given a sample input for my model inside \" \"\n",
        "dummy_input = [\"response port is 8081. transport protocol is tcp. connection state is S0. number of packets sent by the origin is 2. number of IP level bytes sent by the originator is 80. number of IP level bytes sent by the responder is 0\"] * model.config.max_position_embeddings\n",
        "dummy_input = tokenizer(dummy_input, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "eDcuvXpBgIZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model\n",
        "torch.onnx.export(model, dummy_input, \"IoT-23-BERT-Network-Logs-Classification.onnx\", export_params=True)"
      ],
      "metadata": {
        "id": "94n8AtzFgNIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model to your google drive\n",
        "\n",
        "Note!!\n",
        "\n",
        "Change the content inside \" [ ]\""
      ],
      "metadata": {
        "id": "by2MIjqZgR16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M2eFfcUIgNxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = \"[path to drive where you want to download]\"\n",
        "torch.onnx.export(model, dummy_input, export_dir + \"[Name your model].onnx\", export_params=True)"
      ],
      "metadata": {
        "id": "OSgXV2MNgP4W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}